{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dea5d18-7c59-4ec0-b2f5-1ec05a21d2ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b53c5e-e4ad-4520-9536-18d236e547f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import models\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy\n",
    "from torchvision.transforms.v2 import MixUp\n",
    "\n",
    "# Test-Time Augmentation (TTA) Function\n",
    "def tta_predict(model, image, transforms_list, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = [model(transform(image[0]).unsqueeze(0).to(device)) for transform in transforms_list]\n",
    "    return torch.mean(torch.stack(preds), dim=0)\n",
    "\n",
    "# TTA Transforms \n",
    "tta_transforms = [\n",
    "    transforms.Compose([transforms.RandomHorizontalFlip(p=1), transforms.ToTensor()]),\n",
    "    transforms.Compose([transforms.RandomRotation(30), transforms.ToTensor()]),\n",
    "    transforms.Compose([transforms.ColorJitter(brightness=0.2), transforms.ToTensor()])\n",
    "]\n",
    "\n",
    "# Define Training Transform (Now Properly Modified)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    AutoAugment(AutoAugmentPolicy.IMAGENET),  # AutoAugment added\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define Validation & Test Transforms (No TTA Here)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75931eab-352a-4af4-8ade-07095f3f79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset with correct transforms\n",
    "train_dataset = ImageFolder(root='path/to/your/data', transform=train_transform)\n",
    "val_dataset = ImageFolder(root='path/to/your/data', transform=val_test_transform)\n",
    "test_dataset = ImageFolder(root='path/to/your/data', transform=val_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2509bbbd-8098-4d5a-8232-015e787e010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "# Define Custom Model\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        self.base = nn.Sequential(*list(base_model.children())[:-1])  # Remove final FC layer\n",
    "        self.dropout = nn.Dropout(0.5)  # 50% Dropout to prevent overfitting\n",
    "        self.fc = nn.Linear(base_model.fc.in_features, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Load ResNet18 and apply custom classifier\n",
    "base_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "model = CustomResNet(base_model)\n",
    "\n",
    "# Move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = CyclicLR(optimizer, base_lr=1e-5, max_lr=1e-2, step_size_up=2000, mode=\"triangular2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb33825-b80d-490f-87c3-ae726928077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of classes dynamically\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "# Apply MixUp with num_classes\n",
    "torchvision_mixup = MixUp(alpha=0.2, num_classes=num_classes)\n",
    "# Training Loop with Validation\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Convert labels to one-hot encoding\n",
    "        labels = torch.nn.functional.one_hot(labels, num_classes=num_classes).float()\n",
    "        \n",
    "        # Apply MixUp\n",
    "        images, labels = torchvision_mixup(images, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)  # Using loss_fn with label smoothing\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4013d6af-8879-44d0-a5e1-04a7fc272053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd57e2-deaa-42bc-85cf-bbbc1e807ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "torch.save(model.state_dict(), \"path/to/your/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907aa446-edf4-4692-b6f1-df5dafef54c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"path/to/your/model\", map_location=device))\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "image_path = \"path/to/your/test/image\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Adjust based on your model input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "input_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "\n",
    "predicted_class = torch.argmax(output, dim=1).item()\n",
    "print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Predicted: {predicted_class}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
